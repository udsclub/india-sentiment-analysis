{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/pholovnya/Desktop/imdb_small.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Once again Mr. Costner has dragged out a movie...\n",
       "1      0  This is an example of why the majority of acti...\n",
       "2      0  First of all I hate those moronic rappers, who...\n",
       "3      0  Not even the Beatles could write songs everyon...\n",
       "4      0  Brass pictures (movies is not a fitting word f..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "label       \n",
       "0      25000\n",
       "1      25000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        once again mr. costner has dragged out a movie...\n",
       "1        this is an example of why the majority of acti...\n",
       "2        first of all i hate those moronic rappers, who...\n",
       "3        not even the beatles could write songs everyon...\n",
       "4        brass pictures (movies is not a fitting word f...\n",
       "5        a funny thing happened to me while watching \"m...\n",
       "6        this german horror film has to be one of the w...\n",
       "7        being a long-time fan of japanese film, i expe...\n",
       "8        \"tokyo eyes\" tells of a 17 year old japanese g...\n",
       "9        wealthy horse ranchers in buenos aires have a ...\n",
       "10       cage plays a drunk and gets high critically pr...\n",
       "11       first of all, i would like to say that i am a ...\n",
       "12       so tell me - what serious boozer drinks budwei...\n",
       "13       a big disappointment for what was touted as an...\n",
       "14       this film is absolutely appalling and awful. i...\n",
       "15       here's a decidedly average italian post apocal...\n",
       "16       at the bottom end of the apocalypse movie scal...\n",
       "17       earth has been destroyed in a nuclear holocaus...\n",
       "18       many people are standing in front of the house...\n",
       "19       new york family is the last in their neighborh...\n",
       "20       the best thing about \"the prey\" is the tag lin...\n",
       "21       this is truly, without exaggerating, one of th...\n",
       "22       i'm a huge fan of both emily watson (breaking ...\n",
       "23       sure, most of the slasher films of the 1980's ...\n",
       "24       i think that would have been a more appropriat...\n",
       "25       1980 was certainly a year for bad backwoods sl...\n",
       "26       everything everyone has said already pretty mu...\n",
       "27       uhhh ... so, did they even have writers for th...\n",
       "28       oh yeah, this one is definitely a strong conte...\n",
       "29       supercraptastic slasher fare, which feels over...\n",
       "                               ...                        \n",
       "49970    its not as good as the first movie,but its a g...\n",
       "49971    sure, it was cheesy and nonsensical and at tim...\n",
       "49972    spoilers through: <br /><br />i really am in t...\n",
       "49973    i have to say, i loved vanishing point. i've s...\n",
       "49974    to start off with, since this movie is a remak...\n",
       "49975    i have to agree with most of the other posts. ...\n",
       "49976    any movie that shows federal pigs (persons in ...\n",
       "49977    in canadian director kari skogland's film adap...\n",
       "49978    i saw this movie last night after waiting ages...\n",
       "49979    this movie is about basically human relations,...\n",
       "49980    i was surprised at just how much i enjoyed thi...\n",
       "49981    i saw this film in winnipeg recently - appropr...\n",
       "49982    as perhaps one of the few canadians who did no...\n",
       "49983    i was very moved by the story and because i am...\n",
       "49984    what i loved about the on-screen adaptation of...\n",
       "49985    i had a chance to see a screening of this movi...\n",
       "49986    this is a really interesting movie. it is an a...\n",
       "49987    i saw the movie recently and really liked it. ...\n",
       "49988    i thought this movie was hysterical. i have wa...\n",
       "49989    ...this is a classic with so many great dialog...\n",
       "49990    the most hillarious and funny brooks movie i e...\n",
       "49991    \"life stinks\" is a parody of life and death, h...\n",
       "49992    this is the kind of film you want to see with ...\n",
       "49993    i have not read the other comments on the film...\n",
       "49994    life stinks (1991) was a step below mel brooks...\n",
       "49995    seeing as the vote average was pretty low, and...\n",
       "49996    the plot had some wretched, unbelievable twist...\n",
       "49997    i am amazed at how this movie(and most others ...\n",
       "49998    a christmas together actually came before my t...\n",
       "49999    working-class romantic drama from director mar...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvect = CountVectorizer()\n",
    "counts = cvect.fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(data.text, data.label, test_size=0.2, random_state=42, stratify=data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "#stopset = set(stopwords.words('english'))\n",
    "STOPWORDS = ['a','an','by','did','does', 'was', 'were', 'i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport nltk\\nfrom nltk.stem import PorterStemmer\\nimport string\\nstemmer = PorterStemmer()\\ndef tokenize_and_stem(text):\\n    tokens = nltk.tokenize.word_tokenize(text)\\n    # strip out punctuation and make lowercase\\n    tokens = [token.lower().strip(string.punctuation)\\n              for token in tokens if token.isalnum()]\\n\\n    # now stem the tokens\\n    tokens = [stemmer.stem(token) for token in tokens]\\n\\n    return tokens\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Snowball stemmers could be used as a dependency\n",
    "# for cleaning our text\n",
    "'''\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "stemmer = PorterStemmer()\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    # strip out punctuation and make lowercase\n",
    "    tokens = [token.lower().strip(string.punctuation)\n",
    "              for token in tokens if token.isalnum()]\n",
    "\n",
    "    # now stem the tokens\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    return tokens\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.LogisticRegression import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#tokenizer=tokenize_and_stem\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1, 2),stop_words=STOPWORDS)), ('classifier', LogisticRegression())])\n",
    "model = pipeline.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.90      0.91      5000\n",
      "          1       0.90      0.92      0.91      5000\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test)\n",
    "print (accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output_imdb.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(pipeline, 'output_imdb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
